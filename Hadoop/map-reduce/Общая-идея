########################### Общая схема ########################### 

Надо выполнить большие вычисления для которых необходимо использовать мощьности кластера машин.

Для этого существует парадигма Map-Reduce
Вычисления делятся на 2 фазы за которые отвечают 2 типа обработчиков:
1. Map (маперы)
2. Reduce (редъюсеры)

			==== Общая схема Map-Reduce ==== 

 Все данные при этом делятся на НЕЗАВИСИМЫЕ части - split (сплиты).
 Сплиты представляют собой либо целые HDFS блоки либо специальные splitable архивы.

 Каждая часть обрабатывается своим независисым обработчиком.
 Стараются делать так что-бы worker который будет работать со сплитом был на той-же машине что и данные это называется Data Locality,
 тогда передача данных воркеру будет быстрая так как не придется его никуда передавать по сети.

Каждый мапер записывает результат себе на диск в файлы, колличество файлов равно колличеству редъюсеров. Тоесть у каждого маппера 
получается по 1му файлу для каждого редъюсера. 
Результат вычисления маперов представляет из себя <Key, Value>.


Затем данные передаются редъюсерам. Данные с одинаковыми ключами из разных маперов должны придти в один редъюсер.

Процесс копирования из всех мапперов во все редъюсеры и происходит только когда все мапперы отработали и по сети и называется shuffle.

Маперы и редъюсеры работают независимо.
Когда маппер проделал свою работу он складывает результаты маппинга не в HDFS а на локальный диск(если диск сломался маппер все делает с начала).

В итоге в редъюсере должна получиться мапа с уникальным ключем и массивом значений. Т.е. агрегация значений для каждого ключа.

Затем результат пишется в output файлы которые хранятся в HDFS. Колличество вайлов == колличеству редъюсеров
Количество редъюсеров как и формат выходных данных задается пользователем.

Чем больше редъюсеров тем мельче выходные файлы оптимально 500Мб до 1,5Гб для каждого редъюсера.

			==== Map-Reduce без Reduce ==== 

Может быть что фаза Reduce просто не требуется.

Или

Может быть Map-Reduce без Reduce если каждый маппер работает очень долго на пример больше суток тогда чтобы возспользоваться HDFS
можно записать результаты маппинга в output file на случай если диск выйдет из строя. И посылаем результат маппинга в новую Map-Reduce задачу
где фаза Map просто зачитывает готовые данные.

########################### Как именно ########################### 

Нужно:
1)Функцию map() + где лежать входные данные
2)Функцию reduce() + куда складывать результат
3)Все это передается в master который определяет как разбить данные на split-ты. Так же master следит за тем чтобы перезапускать 
мапперы если они упадут.
4)Маперы копируют промежуточные данные в файлы и когда все маперы отработали все данные начинают копироваться на редъюсеры.
5)Редъюсеры в процессе работы пишут выходные файлы в HDFS.
6)Master перезапускает редъюсеры если они падают.
7)Когда все выходные файлы готовы мастер сообщает пользователю.

